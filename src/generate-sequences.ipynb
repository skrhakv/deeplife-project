{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import gettempdir\n",
    "from biotite.structure import get_residues, get_chains\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "cif_file_path = rcsb.fetch(\"1TA6\", \"cif\", gettempdir())\n",
    "cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "\n",
    "whole_auth = get_structure(cif_file, model=1, extra_fields=[\"b_factor\"])\n",
    "# whole_label = get_structure(cif_file, use_author_fields=False)\n",
    "\n",
    "print(len(whole_auth[\n",
    "        (whole_auth.chain_id == \"A\") & \\\n",
    "        (biotite.structure.filter_peptide_backbone(whole_auth))].b_factor))\n",
    "\n",
    "chain_residues = whole_auth[\n",
    "        (whole_auth.chain_id == \"A\") & \\\n",
    "        (biotite.structure.filter_peptide_backbone(whole_auth))]\n",
    "for i in chain_residues:\n",
    "    print(i.b_factor, i.res_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE HOLO SEQUENCES WITH ANNOTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import deeplife_utils\n",
    "import shutil\n",
    "shutil.rmtree('../data/holo-sequence-annotations/', ignore_errors=True)\n",
    "os.makedirs('../data/holo-sequence-annotations', exist_ok=True)\n",
    "\n",
    "with open(f'../cryptobench/whole_dataset.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "    apo_pockets = set()\n",
    "    for holo_structure in holo_structures:\n",
    "\n",
    "        pdb_id = holo_structure['holo_pdb_id']\n",
    "        chain_id = holo_structure['holo_chain']\n",
    "        apo_pocket = holo_structure['apo_pocket_selection']\n",
    "        pocket = holo_structure['holo_pocket_selection']\n",
    "        print(f'Processing {pdb_id}{chain_id} ...')\n",
    "        \n",
    "        # if the pocket too similar to other pockets then don't worry about it\n",
    "        new_apo_residues = [residue.split(\n",
    "            '_')[1] for residue in apo_pocket if residue.split('_')[1] not in apo_pockets]\n",
    "        # probably a homomer or the pocket is just too similar to others \n",
    "        if (len(apo_pocket) - len(new_apo_residues)) / len(apo_pocket) > 0.75:\n",
    "            continue\n",
    "        apo_pockets.update(new_apo_residues)\n",
    "\n",
    "        # auth_seq_ids of the pocket\n",
    "        binding_residues = set([residue.split('_')[1]\n",
    "                               for residue in pocket])\n",
    "\n",
    "        cif_file_path = rcsb.fetch(pdb_id, \"cif\", gettempdir())\n",
    "\n",
    "        cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "        auth = get_structure(cif_file, model=1)\n",
    "\n",
    "        # filter to get correct chain; filter only for peptides\n",
    "        auth_residues_only = get_residues(\n",
    "            auth[\n",
    "                (auth.chain_id == chain_id) &\n",
    "                (biotite.structure.filter_peptide_backbone(auth))\n",
    "            ])\n",
    "\n",
    "        zero_based_binding_residues = []\n",
    "        sequence = \"\"\n",
    "        # to handle cases where residue indices are named like this: 60A, 60B, 60C, ...\n",
    "        previous_seq_id = float('-inf')\n",
    "        letter_counter = 0\n",
    "        for idx, (auth_seq_id, resname) in enumerate(zip(auth_residues_only[0], auth_residues_only[1])):\n",
    "            if previous_seq_id == auth_seq_id:\n",
    "                letter_counter += 1\n",
    "            elif letter_counter > 0:\n",
    "                letter_counter = 0\n",
    "            one_letter_aa = deeplife_utils.three_to_one(resname)\n",
    "            if str(auth_seq_id) in binding_residues or (str(auth_seq_id) + chr(ord('A') + letter_counter)) in binding_residues:\n",
    "                zero_based_binding_residues.append(one_letter_aa + str(idx))\n",
    "            sequence += one_letter_aa\n",
    "            previous_seq_id = auth_seq_id\n",
    "\n",
    "        with open(f'../data/holo-sequence-annotations/{pdb_id.lower()}{chain_id.upper()}.txt', 'w') as f:\n",
    "            f.write(\n",
    "                f'{pdb_id};{chain_id};UNKNOWN;{\" \".join(zero_based_binding_residues)};{sequence}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE APO SEQUENCES WITH ANNOTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import deeplife_utils\n",
    "import shutil\n",
    "shutil.rmtree('../data/apo-sequence-annotations/', ignore_errors=True)\n",
    "os.makedirs('../data/apo-sequence-annotations', exist_ok=True)\n",
    "\n",
    "with open(f'../cryptobench/whole_dataset.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "    binding_residues = set()\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "    for holo_structure in holo_structures:\n",
    "\n",
    "        apo_pocket = holo_structure['apo_pocket_selection']\n",
    "        \n",
    "        new_apo_residues = [residue.split(\n",
    "            '_')[1] for residue in apo_pocket]\n",
    "\n",
    "        binding_residues.update(new_apo_residues)\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", gettempdir())\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1)\n",
    "\n",
    "    # filter to get correct chain; filter only for peptides\n",
    "    auth_residues_only = get_residues(\n",
    "        auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_peptide_backbone(auth))\n",
    "        ])\n",
    "\n",
    "    zero_based_binding_residues = []\n",
    "    sequence = \"\"\n",
    "    # to handle cases where residue indices are named like this: 60A, 60B, 60C, ...\n",
    "    previous_seq_id = float('-inf')\n",
    "    letter_counter = 0\n",
    "    for idx, (auth_seq_id, resname) in enumerate(zip(auth_residues_only[0], auth_residues_only[1])):\n",
    "        if previous_seq_id == auth_seq_id:\n",
    "            letter_counter += 1\n",
    "        elif letter_counter > 0:\n",
    "            letter_counter = 0\n",
    "        one_letter_aa = deeplife_utils.three_to_one(resname)\n",
    "        if str(auth_seq_id) in binding_residues or (str(auth_seq_id) + chr(ord('A') + letter_counter)) in binding_residues:\n",
    "            zero_based_binding_residues.append(one_letter_aa + str(idx))\n",
    "        sequence += one_letter_aa\n",
    "        previous_seq_id = auth_seq_id\n",
    "\n",
    "    with open(f'../data/apo-sequence-annotations/{apo_structure.lower()}{chain_id.upper()}.txt', 'w') as f:\n",
    "        f.write(\n",
    "            f'{apo_structure};{chain_id};UNKNOWN;{\" \".join(zero_based_binding_residues)};{sequence}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "OUTPUT_PATH = '../data/sequences-for-embedder'\n",
    "for path in ['../data/apo-sequence-annotations/', '../data/holo-sequence-annotations/']:\n",
    "    for file in os.listdir(path):\n",
    "        with open(f'{path}{file}', 'r') as f:\n",
    "            csv_reader = csv.reader(f, delimiter=';')\n",
    "            sequence = next(csv_reader)[4]\n",
    "        with open(f'{OUTPUT_PATH}/{file}', 'w') as f:\n",
    "            f.write(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE THREE TXT FILES\n",
    "1. `holo_train.txt`: containing the holo training set\n",
    "2. `holo_test.txt`: containing the holo test set\n",
    "3. `apo_test.txt`: containing the apo test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "DIR_PATH = '/home/skrhakv/deeplife/deeplife-project/'\n",
    "\n",
    "TEST_PATH = DIR_PATH + 'cryptobench/test'\n",
    "TRAIN_PATH = DIR_PATH + 'cryptobench/train'\n",
    "APO_ANNOTATIONS_PATH = DIR_PATH + 'data/apo-sequence-annotations'\n",
    "HOLO_ANNOTATIONS_PATH = DIR_PATH + 'data/holo-sequence-annotations'\n",
    "OUTPUT_PATH = DIR_PATH + 'data'\n",
    "\n",
    "def read_cryptobench_subset(subset_path):\n",
    "    apo_subset = []\n",
    "    holo_subset = []\n",
    "    for file in os.listdir(subset_path):\n",
    "        # load the CryptoBench subset from file\n",
    "        with open(f'{subset_path}/{file}', 'r') as json_file:\n",
    "            dataset = json.load(json_file)\n",
    "        \n",
    "        # read the JSON\n",
    "        for apo_pdb_id, holo_structures in dataset.items():\n",
    "            \n",
    "            # find and read the apo file\n",
    "            apo_chain_id = holo_structures[0]['apo_chain']\n",
    "            apo_filename = f'{APO_ANNOTATIONS_PATH}/{apo_pdb_id}{apo_chain_id}.txt'\n",
    "            if os.path.isfile(apo_filename):\n",
    "                with open(apo_filename, 'r') as apo_file:\n",
    "                    apo_subset.extend(apo_file.readlines())\n",
    "            \n",
    "            # find and read the holo file\n",
    "            for holo_structure in holo_structures:\n",
    "                holo_pdb_id = holo_structure['holo_pdb_id']\n",
    "                holo_chain_id = holo_structure['holo_chain']\n",
    "                holo_filename = f'{HOLO_ANNOTATIONS_PATH}/{holo_pdb_id}{holo_chain_id}.txt'\n",
    "                if os.path.isfile(holo_filename):\n",
    "                    with open(holo_filename, 'r') as holo_file:\n",
    "                        holo_subset.extend(holo_file.readlines())\n",
    "\n",
    "    return apo_subset, holo_subset\n",
    "\n",
    "# extract the annotations\n",
    "train_apo, train_holo = read_cryptobench_subset(TRAIN_PATH)\n",
    "test_apo, test_holo = read_cryptobench_subset(TEST_PATH)\n",
    "\n",
    "# merge the annotations into a single file\n",
    "with open(f'{OUTPUT_PATH}/holo_train.txt', 'w') as holo_train_file:\n",
    "    holo_train_file.write('\\n'.join(train_holo))\n",
    "with open(f'{OUTPUT_PATH}/holo_test.txt', 'w') as holo_test_file:\n",
    "    holo_test_file.write('\\n'.join(test_holo))\n",
    "with open(f'{OUTPUT_PATH}/apo_test.txt', 'w') as apo_test_file:\n",
    "    apo_test_file.write('\\n'.join(test_apo))\n",
    "with open(f'{OUTPUT_PATH}/apo_train.txt', 'w') as apo_train_file:\n",
    "    apo_train_file.write('\\n'.join(train_apo))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
