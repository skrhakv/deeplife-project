{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/skrhakv/deeplife/deeplife-project/data'\n",
    "ESM_EMBEDDINGS_PATH = '/home/skrhakv/esm2/embeddings-3B-deeplife'\n",
    "ADJACENCY_MATRICES_PATH = f'{DATA_PATH}/apo-distance-matrices' \n",
    "PROCESSED_GRAPHS_PATH = f'{DATA_PATH}/processed_graphs'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def process_sequence_dataset(annotation_path, embeddings_paths):\n",
    "    Xs = {}\n",
    "    Ys = {}\n",
    "    with open(annotation_path) as f:\n",
    "        reader = csv.reader(f, delimiter=\";\")\n",
    "        for row in reader:\n",
    "            id = row[0].lower() + row[1]\n",
    "            sequence = row[4]\n",
    "\n",
    "            if row[3] == '':\n",
    "                continue\n",
    "            \n",
    "            # load the precomputed embedding\n",
    "            if id not in Xs:\n",
    "                for embeddings_path in embeddings_paths:\n",
    "                    filename = id + '.npy'\n",
    "                    embedding = np.load(f'{embeddings_path}/{filename}')\n",
    "                    if id not in Xs:\n",
    "                        Xs[id] = embedding\n",
    "                    else:\n",
    "                        Xs[id] = np.concatenate((Xs[id],embedding), axis = 1)\n",
    "                    \n",
    "\n",
    "            # load the annotations denoting whether particular residue is binding or not\n",
    "            # we use binary annotation: 0=non-binding; 1=binding\n",
    "            if id not in Ys:\n",
    "                Ys[id] = np.zeros(embedding.shape[0])\n",
    "            for (aa, residue_idx) in [(residue[0], int(residue[1:])) for residue in row[3].split(' ')]:\n",
    "                assert sequence[residue_idx] == aa\n",
    "                Ys[id][residue_idx] = 1\n",
    "\n",
    "    return Xs, Ys\n",
    "\n",
    "\n",
    "def get_adjacency_info(id):\n",
    "    distance_matrix = np.load(f'{ADJACENCY_MATRICES_PATH}/{id}.npy')\n",
    "\n",
    "    edge_indices = []\n",
    "\n",
    "    for iy, ix in np.ndindex(distance_matrix.shape):\n",
    "        if iy >= ix:\n",
    "            continue\n",
    "\n",
    "        if distance_matrix[iy, ix] <= DISTANCE_THRESHOLD:\n",
    "            edge_indices += [[iy, ix], [ix, iy]]\n",
    "    \n",
    "    edge_indices = torch.tensor(edge_indices)\n",
    "    edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "    return edge_indices\n",
    "\n",
    "\n",
    "def load_dataset(dataset_annotation_filepath):\n",
    "    Xs_train, Ys_train = process_sequence_dataset(dataset_annotation_filepath, [ESM_EMBEDDINGS_PATH])\n",
    "\n",
    "    protein_list = []\n",
    "    for key in Xs_train.keys():\n",
    "        protein_features = torch.tensor(Xs_train[key], dtype=torch.float32)\n",
    "        protein_labels = torch.tensor(Ys_train[key], dtype=torch.int64)\n",
    "        protein_edges = get_adjacency_info(key)\n",
    "        protein = Data(x=protein_features, edge_index=protein_edges, y=protein_labels)\n",
    "        protein_list.append(protein)\n",
    "        if protein_edges.shape[1] > 0:\n",
    "            if protein_edges.max() >= protein_features.size(0):\n",
    "                print(f'{key}: {protein_edges.max()}, {protein_features.size(0)}')\n",
    "        \n",
    "    return protein_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proteins = load_dataset(f'{DATA_PATH}/apo_test.txt')\n",
    "train_proteins = load_dataset(f'{DATA_PATH}/apo_train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COPIED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceCryptoBenchDataset(Dataset):\n",
    "    def __init__(self, _Xs, _Ys):\n",
    "        _Xs_list = []\n",
    "        _Ys_list = []\n",
    "        for key, _ in _Xs.items():\n",
    "            print(f'Processing {key} ...')\n",
    "            _Xs_list.append(_Xs[key])\n",
    "            _Ys_list.append(_Ys[key])\n",
    "\n",
    "        print('Concatenating ...')\n",
    "        Xs_list = np.concatenate(_Xs_list, axis=0)\n",
    "        Ys_list = np.concatenate(_Ys_list, axis=0)\n",
    "\n",
    "        print('Converting to torch tensor ...')\n",
    "        self.Xs = torch.tensor(Xs_list, dtype=torch.float32)\n",
    "        self.Ys = torch.tensor(Ys_list, dtype=torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.Xs) == len(self.Ys)\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.Xs[idx]\n",
    "        y = self.Ys[idx]\n",
    "        return x, y\n",
    "    \n",
    "Xs_train_apo, Ys_train_apo = process_sequence_dataset(f'{DATA_PATH}/apo_train.txt', [ESM_EMBEDDINGS_PATH])\n",
    "train_dataset_apo = SequenceCryptoBenchDataset(Xs_train_apo, Ys_train_apo)\n",
    "\n",
    "Xs_test_apo, Ys_test_apo = process_sequence_dataset(f'{DATA_PATH}/apo_test.txt', [ESM_EMBEDDINGS_PATH])\n",
    "test_dataset_apo = SequenceCryptoBenchDataset(Xs_test_apo, Ys_test_apo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROPOUT = 0.3\n",
    "EMBEDDING_DIM = 2560\n",
    "HEADS = 16\n",
    "HIDDEN_CHANNELS = 8\n",
    "LAYER_WIDTH = 100\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=input_dim, out_features=LAYER_WIDTH)\n",
    "        self.dropout1 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.layer_2 = nn.Linear(in_features=LAYER_WIDTH, out_features=LAYER_WIDTH)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.layer_3 = nn.Linear(in_features=LAYER_WIDTH, out_features=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, _):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       return self.layer_3(self.dropout2(self.relu(self.layer_2(self.dropout1(self.relu(self.layer_1(x)))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  tensor([ 0.5235, 11.1424], device='cuda:0')\n",
      "Epoch: 0 | Loss: 1.00346, Accuracy: 65.87% | Test loss: 1.35119, AUC: 0.4447730893372259, MCC: -0.03196521490097587, sum: 27036.0\n",
      "Epoch: 1 | Loss: 0.86132, Accuracy: 84.13% | Test loss: 0.86205, AUC: 0.7669108046710278, MCC: 0.2197528791782621, sum: 13585.0\n",
      "Epoch: 2 | Loss: 0.74930, Accuracy: 85.52% | Test loss: 0.80664, AUC: 0.8041328652705416, MCC: 0.264461713239608, sum: 12868.0\n",
      "Epoch: 3 | Loss: 0.72686, Accuracy: 86.03% | Test loss: 0.78153, AUC: 0.8192789900766497, MCC: 0.28368596067536894, sum: 12640.0\n",
      "Epoch: 4 | Loss: 0.71378, Accuracy: 86.15% | Test loss: 0.76642, AUC: 0.8275608194125883, MCC: 0.2959321988473, sum: 12725.0\n",
      "Epoch: 5 | Loss: 0.70132, Accuracy: 86.39% | Test loss: 0.75732, AUC: 0.8326808042464886, MCC: 0.3044672641346015, sum: 12605.0\n",
      "Epoch: 6 | Loss: 0.62709, Accuracy: 87.04% | Test loss: 0.75358, AUC: 0.8362217008031798, MCC: 0.3100605668018263, sum: 11969.0\n",
      "Epoch: 7 | Loss: 0.61261, Accuracy: 86.88% | Test loss: 0.74947, AUC: 0.8385858517342508, MCC: 0.31483500325834274, sum: 12238.0\n",
      "Epoch: 8 | Loss: 0.60841, Accuracy: 87.09% | Test loss: 0.74908, AUC: 0.8401593316271472, MCC: 0.3182962674531384, sum: 12062.0\n",
      "Epoch: 9 | Loss: 0.61829, Accuracy: 87.50% | Test loss: 0.75244, AUC: 0.8410498514577633, MCC: 0.32147585732735817, sum: 11642.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;66;03m#if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | Test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MCC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmcc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, sum: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(test_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m fpr_3, tpr_3, roc_auc_3 \u001b[38;5;241m=\u001b[39m train(model, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16384\u001b[39m, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, \n\u001b[1;32m     84\u001b[0m       train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset_apo, test_dataset\u001b[38;5;241m=\u001b[39mtest_dataset_apo)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = torch.tensor([ 0.5235, 11.1424], device='cuda:0')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                            lr=0.0001)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def train(model, optimizer, epochs, batch_size, loss_fn, train_dataset, test_dataset):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create an optimizer\n",
    "    _, y_train = train_dataset[:]\n",
    "    X_test, y_test, = test_dataset[:]\n",
    "\n",
    "    # compute class weights (because the dataset is heavily imbalanced)\n",
    "    print(f'Class weights: ', class_weights)\n",
    "    # BCEWithLogitsLoss - sigmoid is already built-in!\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "\n",
    "    X_test, y_test = X_test.to(device), y_test.to(device).float()\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #\n",
    "        # TEST\n",
    "        #\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            test_logits = model(X_test).squeeze()\n",
    "            test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "            test_loss = loss_fn(test_logits,\n",
    "                                y_test)\n",
    "            test_losses.append(test_loss.cpu().detach().numpy())\n",
    "\n",
    "            # compute metrics on test dataset\n",
    "            test_acc = accuracy_fn(y_true=y_test,\n",
    "                                   y_pred=test_pred)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y_test.cpu().numpy(), torch.sigmoid(test_logits).cpu().numpy())\n",
    "            roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "            mcc = metrics.matthews_corrcoef(y_test.cpu().numpy(), test_pred.cpu().numpy())\n",
    "\n",
    "        #\n",
    "        # TRAIN\n",
    "        #\n",
    "        batch_losses = []\n",
    "        for id_batch, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device).float()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            y_logits = model(x_batch).squeeze()\n",
    "            y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "            loss = loss_fn(y_logits,\n",
    "                           y_batch)\n",
    "            acc = accuracy_fn(y_true=y_batch,\n",
    "                              y_pred=y_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        train_losses.append(sum(batch_losses) / len(batch_losses))\n",
    "        #if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {test_acc:.2f}% | Test loss: {test_loss:.5f}, AUC: {roc_auc}, MCC: {mcc}, sum: {sum(test_pred)}\")\n",
    "\n",
    "fpr_3, tpr_3, roc_auc_3 = train(model, optimizer, epochs=10, batch_size=16384, loss_fn=loss_fn, \n",
    "      train_dataset=train_dataset_apo, test_dataset=test_dataset_apo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# : END OF COPYING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROPOUT = 0.6\n",
    "EMBEDDING_DIM = 2560\n",
    "HEADS = 16\n",
    "HIDDEN_CHANNELS = 100\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.dropout0 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.conv1 = GATConv(EMBEDDING_DIM, HIDDEN_CHANNELS, heads=HEADS, dropout=DROPOUT, concat=False)\n",
    "        # self.dropout00 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        # self.conv2 = GATConv(HIDDEN_CHANNELS * HEADS, HIDDEN_CHANNELS, heads=HEADS,\n",
    "        #                     concat=False, dropout=DROPOUT)\n",
    "\n",
    "        self.linear1 = nn.Linear(HIDDEN_CHANNELS, HIDDEN_CHANNELS * HEADS)\n",
    "        self.dropout1 = nn.Dropout(DROPOUT)\n",
    "        \n",
    "        self.linear2 = nn.Linear(in_features=HIDDEN_CHANNELS * HEADS, out_features=HIDDEN_CHANNELS * HEADS)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.linear3 = nn.Linear(in_features=HIDDEN_CHANNELS * HEADS, out_features=1)\n",
    "        self.dropout3 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout0(x)\n",
    "    \n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.dropout00(x)\n",
    "\n",
    "        # x = self.conv2(x, edge_index)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.dropout3(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  tensor([ 0.5235, 11.1424], device='cuda:0')\n",
      "Epoch: 0 | Loss: 1.63773, Accuracy: 93.73% | Test loss: 1.05802, AUC: 0.4542079866858349, MCC: -0.005317408755528438, sum: 865.0\n",
      "Epoch: 1 | Loss: 1.26348, Accuracy: 57.80% | Test loss: 1.05842, AUC: 0.5976158466350403, MCC: 0.06572505291665946, sum: 36845.0\n",
      "Epoch: 2 | Loss: 1.16847, Accuracy: 90.74% | Test loss: 1.05423, AUC: 0.6185243800925465, MCC: 0.052410215350449034, sum: 4251.0\n",
      "Epoch: 3 | Loss: 1.04990, Accuracy: 58.03% | Test loss: 1.06537, AUC: 0.6281244931044366, MCC: 0.08934022370392815, sum: 37132.0\n",
      "Epoch: 4 | Loss: 1.07636, Accuracy: 39.72% | Test loss: 1.06742, AUC: 0.6496076141053844, MCC: 0.08486675426222876, sum: 54598.0\n",
      "Epoch: 5 | Loss: 0.93725, Accuracy: 30.24% | Test loss: 1.06816, AUC: 0.6427092223904711, MCC: 0.07804728219976384, sum: 63433.0\n",
      "Epoch: 6 | Loss: 0.88445, Accuracy: 26.87% | Test loss: 1.06816, AUC: 0.6388991126735202, MCC: 0.07945305893695291, sum: 66616.0\n",
      "Epoch: 7 | Loss: 0.88470, Accuracy: 26.51% | Test loss: 1.06775, AUC: 0.6453504593785004, MCC: 0.08481924247312221, sum: 67052.0\n",
      "Epoch: 8 | Loss: 0.94987, Accuracy: 34.31% | Test loss: 1.06549, AUC: 0.6648624971071891, MCC: 0.1077046967813379, sum: 60170.0\n",
      "Epoch: 9 | Loss: 0.86036, Accuracy: 36.08% | Test loss: 1.06370, AUC: 0.6921417975894302, MCC: 0.11921685028842804, sum: 58731.0\n",
      "Epoch: 10 | Loss: 0.96779, Accuracy: 44.52% | Test loss: 1.05815, AUC: 0.7268195934867888, MCC: 0.1439311236878816, sum: 51269.0\n",
      "Epoch: 11 | Loss: 1.02684, Accuracy: 51.49% | Test loss: 1.04998, AUC: 0.7580797982721479, MCC: 0.1648258652921283, sum: 45074.0\n",
      "Epoch: 12 | Loss: 0.97700, Accuracy: 57.11% | Test loss: 1.04106, AUC: 0.7761792061234515, MCC: 0.18177696889490025, sum: 40031.0\n",
      "Epoch: 13 | Loss: 0.83728, Accuracy: 61.85% | Test loss: 1.02883, AUC: 0.7932348424983962, MCC: 0.19650248745506116, sum: 35741.0\n",
      "Epoch: 14 | Loss: 0.88421, Accuracy: 64.30% | Test loss: 1.02100, AUC: 0.8023208295101442, MCC: 0.20696957330328877, sum: 33559.0\n",
      "Epoch: 15 | Loss: 0.79853, Accuracy: 67.34% | Test loss: 1.01168, AUC: 0.8096764853325765, MCC: 0.21820294345615132, sum: 30796.0\n",
      "Epoch: 16 | Loss: 0.74055, Accuracy: 69.73% | Test loss: 1.00216, AUC: 0.8150571596003395, MCC: 0.22750295288241473, sum: 28610.0\n",
      "Epoch: 17 | Loss: 0.85860, Accuracy: 70.28% | Test loss: 0.99619, AUC: 0.8188979440190737, MCC: 0.23219742186686812, sum: 28157.0\n",
      "Epoch: 18 | Loss: 0.83279, Accuracy: 72.45% | Test loss: 0.99058, AUC: 0.8222689713462261, MCC: 0.24264361726748251, sum: 26188.0\n",
      "Epoch: 19 | Loss: 0.79147, Accuracy: 73.88% | Test loss: 0.98355, AUC: 0.8249485604159974, MCC: 0.24885555277979585, sum: 24857.0\n",
      "Epoch: 20 | Loss: 0.72930, Accuracy: 73.97% | Test loss: 0.98406, AUC: 0.8271351419719235, MCC: 0.2504787497310707, sum: 24804.0\n",
      "Epoch: 21 | Loss: 0.80530, Accuracy: 74.89% | Test loss: 0.98457, AUC: 0.8290039244575488, MCC: 0.2567365407249294, sum: 23993.0\n",
      "Epoch: 22 | Loss: 0.80961, Accuracy: 75.99% | Test loss: 0.97426, AUC: 0.8306933819348312, MCC: 0.2623873759788319, sum: 22975.0\n",
      "Epoch: 23 | Loss: 0.81474, Accuracy: 76.73% | Test loss: 0.97160, AUC: 0.8324978072730583, MCC: 0.2665187008135095, sum: 22294.0\n",
      "Epoch: 24 | Loss: 0.78943, Accuracy: 77.15% | Test loss: 0.97077, AUC: 0.8338446417497614, MCC: 0.26887426690735666, sum: 21904.0\n",
      "Epoch: 25 | Loss: 0.80105, Accuracy: 77.56% | Test loss: 0.97789, AUC: 0.8351459971577813, MCC: 0.271060392313088, sum: 21525.0\n",
      "Epoch: 26 | Loss: 0.72708, Accuracy: 78.01% | Test loss: 0.96952, AUC: 0.8362938933509156, MCC: 0.2738832689274376, sum: 21104.0\n",
      "Epoch: 27 | Loss: 0.70221, Accuracy: 78.14% | Test loss: 0.97070, AUC: 0.8373405694561129, MCC: 0.27503192885491345, sum: 20998.0\n",
      "Epoch: 28 | Loss: 0.77739, Accuracy: 78.20% | Test loss: 0.97069, AUC: 0.8382441942649728, MCC: 0.27621196651812274, sum: 20956.0\n",
      "Epoch: 29 | Loss: 0.76788, Accuracy: 78.86% | Test loss: 0.97201, AUC: 0.83904833051429, MCC: 0.2794910228333222, sum: 20332.0\n",
      "Epoch: 30 | Loss: 0.73832, Accuracy: 79.35% | Test loss: 0.96737, AUC: 0.8401434853970675, MCC: 0.28339267362475157, sum: 19893.0\n",
      "Epoch: 31 | Loss: 0.86130, Accuracy: 79.09% | Test loss: 0.96706, AUC: 0.8408110947168985, MCC: 0.2815334743751527, sum: 20130.0\n",
      "Epoch: 32 | Loss: 0.77703, Accuracy: 79.93% | Test loss: 0.96524, AUC: 0.8416341559153819, MCC: 0.285848663646368, sum: 19325.0\n",
      "Epoch: 33 | Loss: 0.71283, Accuracy: 79.69% | Test loss: 0.97042, AUC: 0.8423269346676767, MCC: 0.2846826120027022, sum: 19560.0\n",
      "Epoch: 34 | Loss: 0.81589, Accuracy: 80.25% | Test loss: 0.95776, AUC: 0.8427654733602374, MCC: 0.2874722010200556, sum: 19013.0\n",
      "Epoch: 35 | Loss: 0.76191, Accuracy: 79.88% | Test loss: 0.96461, AUC: 0.8433278250375218, MCC: 0.28731666824815605, sum: 19410.0\n",
      "Epoch: 36 | Loss: 0.82539, Accuracy: 80.98% | Test loss: 0.95641, AUC: 0.843824433541199, MCC: 0.29282766757023887, sum: 18344.0\n",
      "Epoch: 37 | Loss: 0.71542, Accuracy: 80.37% | Test loss: 0.96123, AUC: 0.8443224655674464, MCC: 0.29055401798228775, sum: 18944.0\n",
      "Epoch: 38 | Loss: 0.74420, Accuracy: 81.01% | Test loss: 0.96350, AUC: 0.8447634669674453, MCC: 0.29414078571061125, sum: 18340.0\n",
      "Epoch: 39 | Loss: 0.73739, Accuracy: 80.18% | Test loss: 0.96040, AUC: 0.8451863161111501, MCC: 0.28974770664218424, sum: 19134.0\n",
      "Epoch: 40 | Loss: 0.68903, Accuracy: 80.20% | Test loss: 0.96384, AUC: 0.845405985865002, MCC: 0.28918646866945696, sum: 19098.0\n",
      "Epoch: 41 | Loss: 0.77162, Accuracy: 80.50% | Test loss: 0.95722, AUC: 0.8456930874678716, MCC: 0.2909926953126309, sum: 18816.0\n",
      "Epoch: 42 | Loss: 0.76299, Accuracy: 80.30% | Test loss: 0.95735, AUC: 0.8458999281095658, MCC: 0.2900137379168465, sum: 19009.0\n",
      "Epoch: 43 | Loss: 0.69218, Accuracy: 81.22% | Test loss: 0.94993, AUC: 0.8461086274994516, MCC: 0.29538432330009606, sum: 18132.0\n",
      "Epoch: 44 | Loss: 0.79434, Accuracy: 81.04% | Test loss: 0.95102, AUC: 0.8463781044733955, MCC: 0.29560566691210616, sum: 18334.0\n",
      "Epoch: 45 | Loss: 0.69689, Accuracy: 81.22% | Test loss: 0.95114, AUC: 0.8468698813030991, MCC: 0.29658688661703436, sum: 18157.0\n",
      "Epoch: 46 | Loss: 0.78822, Accuracy: 81.12% | Test loss: 0.94463, AUC: 0.8471317023235769, MCC: 0.29676962257379413, sum: 18272.0\n",
      "Epoch: 47 | Loss: 0.71793, Accuracy: 81.17% | Test loss: 0.94703, AUC: 0.8473007707379725, MCC: 0.2966838175333807, sum: 18219.0\n",
      "Epoch: 48 | Loss: 0.75522, Accuracy: 80.98% | Test loss: 0.94443, AUC: 0.847412630418404, MCC: 0.2961111681104519, sum: 18404.0\n",
      "Epoch: 49 | Loss: 0.73899, Accuracy: 81.37% | Test loss: 0.95023, AUC: 0.8476091287601824, MCC: 0.2977458355795791, sum: 18017.0\n",
      "Epoch: 50 | Loss: 0.85655, Accuracy: 81.48% | Test loss: 0.94693, AUC: 0.8476884389207697, MCC: 0.2984887005881799, sum: 17920.0\n",
      "Epoch: 51 | Loss: 0.67391, Accuracy: 81.58% | Test loss: 0.94845, AUC: 0.847865271760248, MCC: 0.29941511946256566, sum: 17829.0\n",
      "Epoch: 52 | Loss: 0.65762, Accuracy: 82.29% | Test loss: 0.93326, AUC: 0.8481434853863545, MCC: 0.30257779043573557, sum: 17117.0\n",
      "Epoch: 53 | Loss: 0.69938, Accuracy: 80.62% | Test loss: 0.96208, AUC: 0.848269955256101, MCC: 0.29437227968752, sum: 18755.0\n",
      "Epoch: 54 | Loss: 0.75526, Accuracy: 81.18% | Test loss: 0.94904, AUC: 0.8484724757813213, MCC: 0.297494302904901, sum: 18215.0\n",
      "Epoch: 55 | Loss: 0.73723, Accuracy: 81.66% | Test loss: 0.94398, AUC: 0.8485652913277242, MCC: 0.2995156947025495, sum: 17743.0\n",
      "Epoch: 56 | Loss: 0.79703, Accuracy: 81.76% | Test loss: 0.93031, AUC: 0.8487092170927708, MCC: 0.2995243216807934, sum: 17635.0\n",
      "Epoch: 57 | Loss: 0.76488, Accuracy: 81.79% | Test loss: 0.94140, AUC: 0.8490005731934822, MCC: 0.3005301587825198, sum: 17617.0\n",
      "Epoch: 58 | Loss: 0.68354, Accuracy: 81.51% | Test loss: 0.94622, AUC: 0.8492092899923929, MCC: 0.29876294366252193, sum: 17889.0\n",
      "Epoch: 59 | Loss: 0.75400, Accuracy: 81.87% | Test loss: 0.93879, AUC: 0.8489830182006561, MCC: 0.3001662590754563, sum: 17528.0\n",
      "Epoch: 60 | Loss: 0.64558, Accuracy: 81.88% | Test loss: 0.94480, AUC: 0.8490701905446965, MCC: 0.3002986459944753, sum: 17518.0\n",
      "Epoch: 61 | Loss: 0.74048, Accuracy: 82.14% | Test loss: 0.93442, AUC: 0.8493048400948526, MCC: 0.3024853790191852, sum: 17277.0\n",
      "Epoch: 62 | Loss: 0.64246, Accuracy: 81.63% | Test loss: 0.94751, AUC: 0.8495321537497689, MCC: 0.2999526457028562, sum: 17778.0\n",
      "Epoch: 63 | Loss: 0.66864, Accuracy: 82.25% | Test loss: 0.93330, AUC: 0.8496191292379127, MCC: 0.3026500842548578, sum: 17169.0\n",
      "Epoch: 64 | Loss: 0.76271, Accuracy: 81.46% | Test loss: 0.94937, AUC: 0.8496076781170296, MCC: 0.2998783269080934, sum: 17970.0\n",
      "Epoch: 65 | Loss: 0.68033, Accuracy: 82.00% | Test loss: 0.93753, AUC: 0.8497592651921657, MCC: 0.3010554489758202, sum: 17403.0\n",
      "Epoch: 66 | Loss: 0.65955, Accuracy: 82.01% | Test loss: 0.94404, AUC: 0.8499868962269963, MCC: 0.30130429395417235, sum: 17394.0\n",
      "Epoch: 67 | Loss: 0.71279, Accuracy: 81.99% | Test loss: 0.94856, AUC: 0.8500373167804255, MCC: 0.30168511135890036, sum: 17433.0\n",
      "Epoch: 68 | Loss: 0.76419, Accuracy: 82.27% | Test loss: 0.93868, AUC: 0.8500144440000859, MCC: 0.30274329875545974, sum: 17143.0\n",
      "Epoch: 69 | Loss: 0.66971, Accuracy: 82.26% | Test loss: 0.94475, AUC: 0.8501715189355165, MCC: 0.30225247580202963, sum: 17141.0\n",
      "Epoch: 70 | Loss: 0.75462, Accuracy: 82.05% | Test loss: 0.94258, AUC: 0.8502173595762545, MCC: 0.30104377325431697, sum: 17346.0\n",
      "Epoch: 71 | Loss: 0.74314, Accuracy: 81.82% | Test loss: 0.94912, AUC: 0.8503226038272435, MCC: 0.30069217812822824, sum: 17595.0\n",
      "Epoch: 72 | Loss: 0.71506, Accuracy: 82.35% | Test loss: 0.93527, AUC: 0.8503735171899913, MCC: 0.3028338685175948, sum: 17060.0\n",
      "Epoch: 73 | Loss: 0.73003, Accuracy: 82.64% | Test loss: 0.92486, AUC: 0.8506051897968984, MCC: 0.30537189075026244, sum: 16790.0\n",
      "Epoch: 74 | Loss: 0.72168, Accuracy: 82.23% | Test loss: 0.92902, AUC: 0.850615162489825, MCC: 0.3030475207527486, sum: 17197.0\n",
      "Epoch: 75 | Loss: 0.79817, Accuracy: 81.77% | Test loss: 0.94620, AUC: 0.8507114451104842, MCC: 0.3007132796237188, sum: 17642.0\n",
      "Epoch: 76 | Loss: 0.75122, Accuracy: 81.95% | Test loss: 0.93056, AUC: 0.8511041592321761, MCC: 0.3018220751994851, sum: 17471.0\n",
      "Epoch: 77 | Loss: 0.78315, Accuracy: 82.10% | Test loss: 0.93108, AUC: 0.8511532125075766, MCC: 0.3023215569752862, sum: 17318.0\n",
      "Epoch: 78 | Loss: 0.67587, Accuracy: 82.24% | Test loss: 0.93332, AUC: 0.8510655902072017, MCC: 0.30346255407476813, sum: 17195.0\n",
      "Epoch: 79 | Loss: 0.79405, Accuracy: 82.48% | Test loss: 0.92524, AUC: 0.8511836086649623, MCC: 0.3044536528720428, sum: 16951.0\n",
      "Epoch: 80 | Loss: 0.71884, Accuracy: 82.41% | Test loss: 0.92170, AUC: 0.8513621234840719, MCC: 0.3042469502564916, sum: 17023.0\n",
      "Epoch: 81 | Loss: 0.72448, Accuracy: 82.45% | Test loss: 0.93836, AUC: 0.8512636526829049, MCC: 0.30440475258992344, sum: 16983.0\n",
      "Epoch: 82 | Loss: 0.70300, Accuracy: 82.78% | Test loss: 0.92415, AUC: 0.8513246458710402, MCC: 0.3058969441973257, sum: 16649.0\n",
      "Epoch: 83 | Loss: 0.74936, Accuracy: 82.50% | Test loss: 0.93473, AUC: 0.8514325845034133, MCC: 0.30420157845509327, sum: 16922.0\n",
      "Epoch: 84 | Loss: 0.63308, Accuracy: 82.72% | Test loss: 0.92393, AUC: 0.8515941737329028, MCC: 0.30630305117352025, sum: 16723.0\n",
      "Epoch: 85 | Loss: 0.70069, Accuracy: 82.58% | Test loss: 0.93040, AUC: 0.8517029359460669, MCC: 0.30604839499918024, sum: 16873.0\n",
      "Epoch: 86 | Loss: 0.66126, Accuracy: 82.68% | Test loss: 0.92210, AUC: 0.851661060545527, MCC: 0.30685753892759915, sum: 16777.0\n",
      "Epoch: 87 | Loss: 0.72699, Accuracy: 82.43% | Test loss: 0.93644, AUC: 0.8517156204294029, MCC: 0.3058797762360005, sum: 17027.0\n",
      "Epoch: 88 | Loss: 0.71596, Accuracy: 82.61% | Test loss: 0.92357, AUC: 0.8517198762664004, MCC: 0.3057643517082252, sum: 16837.0\n",
      "Epoch: 89 | Loss: 0.63871, Accuracy: 82.36% | Test loss: 0.93642, AUC: 0.8518121909685499, MCC: 0.3036873374642003, sum: 17064.0\n",
      "Epoch: 90 | Loss: 0.68421, Accuracy: 82.63% | Test loss: 0.91569, AUC: 0.8518326371986567, MCC: 0.3057747440659671, sum: 16808.0\n",
      "Epoch: 91 | Loss: 0.76505, Accuracy: 82.40% | Test loss: 0.92350, AUC: 0.8519387559183553, MCC: 0.3036115114684204, sum: 17022.0\n",
      "Epoch: 92 | Loss: 0.74231, Accuracy: 82.46% | Test loss: 0.93631, AUC: 0.8519477108529064, MCC: 0.30471945900815206, sum: 16979.0\n",
      "Epoch: 93 | Loss: 0.67190, Accuracy: 82.67% | Test loss: 0.92064, AUC: 0.8518763780431668, MCC: 0.30626044042597006, sum: 16773.0\n",
      "Epoch: 94 | Loss: 0.73655, Accuracy: 82.70% | Test loss: 0.91949, AUC: 0.8520532282916699, MCC: 0.3067162526870463, sum: 16759.0\n",
      "Epoch: 95 | Loss: 0.75138, Accuracy: 82.58% | Test loss: 0.91402, AUC: 0.8520900898930531, MCC: 0.3061648279306621, sum: 16874.0\n",
      "Epoch: 96 | Loss: 0.66963, Accuracy: 82.64% | Test loss: 0.93303, AUC: 0.8521000411594878, MCC: 0.3067821850612628, sum: 16820.0\n",
      "Epoch: 97 | Loss: 0.67291, Accuracy: 82.50% | Test loss: 0.93424, AUC: 0.8523023514372541, MCC: 0.3058701862565931, sum: 16952.0\n",
      "Epoch: 98 | Loss: 0.72204, Accuracy: 82.72% | Test loss: 0.92883, AUC: 0.8525636501869865, MCC: 0.3077000603921298, sum: 16754.0\n",
      "Epoch: 99 | Loss: 0.73155, Accuracy: 82.35% | Test loss: 0.92453, AUC: 0.8526100064026911, MCC: 0.30585746972720157, sum: 17114.0\n",
      "Epoch: 100 | Loss: 0.75938, Accuracy: 82.17% | Test loss: 0.94004, AUC: 0.8526999615123957, MCC: 0.30570216006795253, sum: 17316.0\n",
      "Epoch: 101 | Loss: 0.76425, Accuracy: 82.35% | Test loss: 0.92864, AUC: 0.852694507130995, MCC: 0.3064777296100841, sum: 17135.0\n",
      "Epoch: 102 | Loss: 0.70258, Accuracy: 82.69% | Test loss: 0.93379, AUC: 0.8526488553112189, MCC: 0.30872805191154506, sum: 16802.0\n",
      "Epoch: 103 | Loss: 0.75180, Accuracy: 82.77% | Test loss: 0.92109, AUC: 0.8527084986303503, MCC: 0.3094583734503663, sum: 16731.0\n",
      "Epoch: 104 | Loss: 0.63076, Accuracy: 82.78% | Test loss: 0.92307, AUC: 0.8528180589803459, MCC: 0.3092016343414575, sum: 16712.0\n",
      "Epoch: 105 | Loss: 0.73891, Accuracy: 82.99% | Test loss: 0.92111, AUC: 0.8527738333614515, MCC: 0.31065447400885016, sum: 16516.0\n",
      "Epoch: 106 | Loss: 0.70217, Accuracy: 82.80% | Test loss: 0.92787, AUC: 0.8530192818636372, MCC: 0.3106905145010332, sum: 16727.0\n",
      "Epoch: 107 | Loss: 0.66299, Accuracy: 82.77% | Test loss: 0.92490, AUC: 0.8532338039027567, MCC: 0.30980836593632655, sum: 16734.0\n",
      "Epoch: 108 | Loss: 0.68511, Accuracy: 82.90% | Test loss: 0.92297, AUC: 0.8530723726936468, MCC: 0.3110611545458316, sum: 16617.0\n",
      "Epoch: 109 | Loss: 0.72616, Accuracy: 82.75% | Test loss: 0.92496, AUC: 0.8529980763322157, MCC: 0.3107036097839385, sum: 16782.0\n",
      "Epoch: 110 | Loss: 0.78646, Accuracy: 83.03% | Test loss: 0.92498, AUC: 0.8529094054728827, MCC: 0.31204965179317, sum: 16501.0\n",
      "Epoch: 111 | Loss: 0.68534, Accuracy: 82.64% | Test loss: 0.92484, AUC: 0.8531197788074654, MCC: 0.3100913327677057, sum: 16882.0\n",
      "Epoch: 112 | Loss: 0.67668, Accuracy: 83.00% | Test loss: 0.92488, AUC: 0.8531723928980253, MCC: 0.31169420113351615, sum: 16526.0\n",
      "Epoch: 113 | Loss: 0.62072, Accuracy: 83.07% | Test loss: 0.92442, AUC: 0.8532543358388321, MCC: 0.31157584729634613, sum: 16442.0\n",
      "Epoch: 114 | Loss: 0.72097, Accuracy: 82.66% | Test loss: 0.91717, AUC: 0.8533244888523492, MCC: 0.3091119266983527, sum: 16840.0\n",
      "Epoch: 115 | Loss: 0.69108, Accuracy: 82.65% | Test loss: 0.92900, AUC: 0.8534794586349289, MCC: 0.30945757680732916, sum: 16862.0\n",
      "Epoch: 116 | Loss: 0.66408, Accuracy: 82.97% | Test loss: 0.92507, AUC: 0.8534331640203892, MCC: 0.3100762980463798, sum: 16529.0\n",
      "Epoch: 117 | Loss: 0.64958, Accuracy: 83.27% | Test loss: 0.91274, AUC: 0.8534016657378148, MCC: 0.31170036725649397, sum: 16222.0\n",
      "Epoch: 118 | Loss: 0.69909, Accuracy: 83.29% | Test loss: 0.91043, AUC: 0.8534799568008709, MCC: 0.3117393103937628, sum: 16201.0\n",
      "Epoch: 119 | Loss: 0.65820, Accuracy: 83.08% | Test loss: 0.93215, AUC: 0.8535626764520172, MCC: 0.31104325326245785, sum: 16424.0\n",
      "Epoch: 120 | Loss: 0.69741, Accuracy: 83.25% | Test loss: 0.91420, AUC: 0.8536114926968486, MCC: 0.311870588420853, sum: 16256.0\n",
      "Epoch: 121 | Loss: 0.63643, Accuracy: 83.51% | Test loss: 0.91589, AUC: 0.8535621488246485, MCC: 0.3134714399338856, sum: 15991.0\n",
      "Epoch: 122 | Loss: 0.67879, Accuracy: 83.07% | Test loss: 0.91994, AUC: 0.8535712443705541, MCC: 0.31072302789543, sum: 16428.0\n",
      "Epoch: 123 | Loss: 0.66814, Accuracy: 82.93% | Test loss: 0.93689, AUC: 0.8536624060595962, MCC: 0.3101239398887712, sum: 16572.0\n",
      "Epoch: 124 | Loss: 0.68397, Accuracy: 83.41% | Test loss: 0.91199, AUC: 0.8537425451575976, MCC: 0.31323604251597675, sum: 16107.0\n",
      "Epoch: 125 | Loss: 0.64366, Accuracy: 83.17% | Test loss: 0.93159, AUC: 0.8538093609949667, MCC: 0.31148048726041233, sum: 16329.0\n",
      "Epoch: 126 | Loss: 0.71272, Accuracy: 83.25% | Test loss: 0.92675, AUC: 0.8538461315337587, MCC: 0.3115439290823816, sum: 16242.0\n",
      "Epoch: 127 | Loss: 0.66760, Accuracy: 83.19% | Test loss: 0.91032, AUC: 0.8540843084201805, MCC: 0.3112543156752811, sum: 16308.0\n",
      "Epoch: 128 | Loss: 0.66365, Accuracy: 82.43% | Test loss: 0.92824, AUC: 0.8540941753198025, MCC: 0.30740124883278314, sum: 17058.0\n",
      "Epoch: 129 | Loss: 0.68644, Accuracy: 82.83% | Test loss: 0.91851, AUC: 0.854057036513177, MCC: 0.30939386391499596, sum: 16661.0\n",
      "Epoch: 130 | Loss: 0.70308, Accuracy: 82.87% | Test loss: 0.91989, AUC: 0.8540344677211945, MCC: 0.30978766842119787, sum: 16633.0\n",
      "Epoch: 131 | Loss: 0.76354, Accuracy: 82.96% | Test loss: 0.92381, AUC: 0.854106242452334, MCC: 0.31010842460683885, sum: 16536.0\n",
      "Epoch: 132 | Loss: 0.74027, Accuracy: 83.00% | Test loss: 0.92417, AUC: 0.8541953605896899, MCC: 0.3106508692589774, sum: 16507.0\n",
      "Epoch: 133 | Loss: 0.73495, Accuracy: 83.36% | Test loss: 0.91628, AUC: 0.8541802067031371, MCC: 0.31355547142290496, sum: 16167.0\n",
      "Epoch: 134 | Loss: 0.77800, Accuracy: 83.05% | Test loss: 0.92100, AUC: 0.8542239796873855, MCC: 0.31120199472570675, sum: 16459.0\n",
      "Epoch: 135 | Loss: 0.66831, Accuracy: 82.95% | Test loss: 0.92031, AUC: 0.8542633722931507, MCC: 0.31105237582046663, sum: 16562.0\n",
      "Epoch: 136 | Loss: 0.70866, Accuracy: 82.73% | Test loss: 0.93102, AUC: 0.8541730877511299, MCC: 0.3094214806709902, sum: 16771.0\n",
      "Epoch: 137 | Loss: 0.71794, Accuracy: 82.59% | Test loss: 0.92559, AUC: 0.8542792292364764, MCC: 0.3091180736210145, sum: 16924.0\n",
      "Epoch: 138 | Loss: 0.74596, Accuracy: 82.96% | Test loss: 0.92073, AUC: 0.8544483097032738, MCC: 0.3106796594101228, sum: 16542.0\n",
      "Epoch: 139 | Loss: 0.64394, Accuracy: 82.84% | Test loss: 0.92974, AUC: 0.8544688309261032, MCC: 0.30994550133101284, sum: 16659.0\n",
      "Epoch: 140 | Loss: 0.68849, Accuracy: 86.60% | Test loss: 0.90900, AUC: 0.8541896370379821, MCC: 0.3364249878740348, sum: 12952.0\n",
      "Epoch: 141 | Loss: 0.68332, Accuracy: 86.54% | Test loss: 0.91156, AUC: 0.8541464894394726, MCC: 0.3360634729157371, sum: 13011.0\n",
      "Epoch: 142 | Loss: 0.73487, Accuracy: 86.73% | Test loss: 0.91080, AUC: 0.8541034610258256, MCC: 0.3373267998205585, sum: 12825.0\n",
      "Epoch: 143 | Loss: 0.68585, Accuracy: 86.63% | Test loss: 0.90324, AUC: 0.8541140256255971, MCC: 0.3369383661424541, sum: 12932.0\n",
      "Epoch: 144 | Loss: 0.64306, Accuracy: 86.49% | Test loss: 0.91297, AUC: 0.8542990192802621, MCC: 0.3364423221960771, sum: 13077.0\n",
      "Epoch: 145 | Loss: 0.65918, Accuracy: 86.58% | Test loss: 0.92367, AUC: 0.8543542085673438, MCC: 0.33698977346060116, sum: 12992.0\n",
      "Epoch: 146 | Loss: 0.69673, Accuracy: 86.74% | Test loss: 0.92198, AUC: 0.8542078361647277, MCC: 0.3377289447110841, sum: 12819.0\n",
      "Epoch: 147 | Loss: 0.65166, Accuracy: 86.65% | Test loss: 0.92301, AUC: 0.8543950126432774, MCC: 0.33732637296176105, sum: 12911.0\n",
      "Epoch: 148 | Loss: 0.68894, Accuracy: 86.63% | Test loss: 0.92306, AUC: 0.8544907261227397, MCC: 0.337335551429816, sum: 12934.0\n",
      "Epoch: 149 | Loss: 0.72295, Accuracy: 86.75% | Test loss: 0.90799, AUC: 0.8547372379145967, MCC: 0.33877883540273307, sum: 12825.0\n",
      "Epoch: 150 | Loss: 0.64860, Accuracy: 87.06% | Test loss: 0.91419, AUC: 0.854652553721954, MCC: 0.34140932830246973, sum: 12516.0\n",
      "Epoch: 151 | Loss: 0.66795, Accuracy: 86.73% | Test loss: 0.92418, AUC: 0.8546393242022249, MCC: 0.33887479074295, sum: 12851.0\n",
      "Epoch: 152 | Loss: 0.66286, Accuracy: 86.72% | Test loss: 0.93252, AUC: 0.8544554701691097, MCC: 0.3391051397448229, sum: 12862.0\n",
      "Epoch: 153 | Loss: 0.72903, Accuracy: 86.73% | Test loss: 0.91651, AUC: 0.8546404906068896, MCC: 0.33993804222545154, sum: 12864.0\n",
      "Epoch: 154 | Loss: 0.66945, Accuracy: 86.94% | Test loss: 0.91778, AUC: 0.8545804468801865, MCC: 0.34078328639601624, sum: 12641.0\n",
      "Epoch: 155 | Loss: 0.69197, Accuracy: 86.81% | Test loss: 0.91853, AUC: 0.8546585785837074, MCC: 0.3401268651600617, sum: 12784.0\n",
      "Epoch: 156 | Loss: 0.66562, Accuracy: 86.69% | Test loss: 0.91649, AUC: 0.8549966069408823, MCC: 0.3387630176965777, sum: 12896.0\n",
      "Epoch: 157 | Loss: 0.79064, Accuracy: 86.97% | Test loss: 0.92975, AUC: 0.8550873146561226, MCC: 0.3410797014236268, sum: 12610.0\n",
      "Epoch: 158 | Loss: 0.71201, Accuracy: 86.86% | Test loss: 0.91733, AUC: 0.8552646081651815, MCC: 0.3396578889457579, sum: 12716.0\n",
      "Epoch: 159 | Loss: 0.60599, Accuracy: 86.93% | Test loss: 0.91254, AUC: 0.8552788594607535, MCC: 0.34021794223112595, sum: 12640.0\n",
      "Epoch: 160 | Loss: 0.67107, Accuracy: 87.12% | Test loss: 0.90956, AUC: 0.855064176722943, MCC: 0.3406914865760457, sum: 12431.0\n",
      "Epoch: 161 | Loss: 0.61466, Accuracy: 87.10% | Test loss: 0.91658, AUC: 0.8549526987019025, MCC: 0.3403260954872108, sum: 12450.0\n",
      "Epoch: 162 | Loss: 0.62432, Accuracy: 86.89% | Test loss: 0.92212, AUC: 0.8549792715696003, MCC: 0.33941007151376185, sum: 12675.0\n",
      "Epoch: 163 | Loss: 0.76637, Accuracy: 87.09% | Test loss: 0.92614, AUC: 0.8551414701149594, MCC: 0.3406066428969283, sum: 12466.0\n",
      "Epoch: 164 | Loss: 0.71083, Accuracy: 87.00% | Test loss: 0.90950, AUC: 0.8554333029551207, MCC: 0.3403778179284188, sum: 12570.0\n",
      "Epoch: 165 | Loss: 0.60882, Accuracy: 86.95% | Test loss: 0.91489, AUC: 0.8553999044105264, MCC: 0.34021007957958704, sum: 12625.0\n",
      "Epoch: 166 | Loss: 0.63317, Accuracy: 86.95% | Test loss: 0.91374, AUC: 0.8554169987337721, MCC: 0.34030494245465925, sum: 12620.0\n",
      "Epoch: 167 | Loss: 0.69678, Accuracy: 87.01% | Test loss: 0.91002, AUC: 0.8554301867396727, MCC: 0.3414346438931426, sum: 12576.0\n",
      "Epoch: 168 | Loss: 0.66364, Accuracy: 86.99% | Test loss: 0.92073, AUC: 0.855552637802991, MCC: 0.3405563353481827, sum: 12576.0\n",
      "Epoch: 169 | Loss: 0.72177, Accuracy: 87.18% | Test loss: 0.91127, AUC: 0.8555671435381572, MCC: 0.34194370340343067, sum: 12389.0\n",
      "Epoch: 170 | Loss: 0.69226, Accuracy: 86.94% | Test loss: 0.92415, AUC: 0.8556770051981982, MCC: 0.3403885504168967, sum: 12631.0\n",
      "Epoch: 171 | Loss: 0.60382, Accuracy: 86.80% | Test loss: 0.91516, AUC: 0.8556756419376369, MCC: 0.3395827537862675, sum: 12782.0\n",
      "Epoch: 172 | Loss: 0.59807, Accuracy: 87.01% | Test loss: 0.89634, AUC: 0.8557090779785924, MCC: 0.34122435514059185, sum: 12564.0\n",
      "Epoch: 173 | Loss: 0.67157, Accuracy: 87.24% | Test loss: 0.90662, AUC: 0.8555384454302719, MCC: 0.3427549266722711, sum: 12332.0\n",
      "Epoch: 174 | Loss: 0.62644, Accuracy: 87.28% | Test loss: 0.91062, AUC: 0.8555797275848112, MCC: 0.3436546414831195, sum: 12301.0\n",
      "Epoch: 175 | Loss: 0.79674, Accuracy: 87.38% | Test loss: 0.92126, AUC: 0.8555917625776046, MCC: 0.3439869462109944, sum: 12186.0\n",
      "Epoch: 176 | Loss: 0.70152, Accuracy: 87.39% | Test loss: 0.92053, AUC: 0.8554981167546322, MCC: 0.34410525670421693, sum: 12180.0\n",
      "Epoch: 177 | Loss: 0.75797, Accuracy: 87.02% | Test loss: 0.91097, AUC: 0.8555524248772254, MCC: 0.3407210053895092, sum: 12552.0\n",
      "Epoch: 178 | Loss: 0.69366, Accuracy: 86.98% | Test loss: 0.91020, AUC: 0.8555367326500579, MCC: 0.341174808887597, sum: 12605.0\n",
      "Epoch: 179 | Loss: 0.72475, Accuracy: 87.02% | Test loss: 0.92489, AUC: 0.855600373349126, MCC: 0.3410712966358026, sum: 12549.0\n",
      "Epoch: 180 | Loss: 0.65883, Accuracy: 87.21% | Test loss: 0.91815, AUC: 0.8556054768717182, MCC: 0.34280064223000317, sum: 12360.0\n",
      "Epoch: 181 | Loss: 0.68695, Accuracy: 87.26% | Test loss: 0.91611, AUC: 0.8554937270020588, MCC: 0.343283870286161, sum: 12320.0\n",
      "Epoch: 182 | Loss: 0.59472, Accuracy: 87.03% | Test loss: 0.90406, AUC: 0.8556166789096302, MCC: 0.34107760409003185, sum: 12541.0\n",
      "Epoch: 183 | Loss: 0.70219, Accuracy: 87.17% | Test loss: 0.90520, AUC: 0.8555317362599265, MCC: 0.3414511963921406, sum: 12384.0\n",
      "Epoch: 184 | Loss: 0.62372, Accuracy: 87.11% | Test loss: 0.91030, AUC: 0.8556479120393646, MCC: 0.34073545633293617, sum: 12444.0\n",
      "Epoch: 185 | Loss: 0.64767, Accuracy: 87.19% | Test loss: 0.90314, AUC: 0.8558883695080415, MCC: 0.3417920897794996, sum: 12374.0\n",
      "Epoch: 186 | Loss: 0.69327, Accuracy: 87.15% | Test loss: 0.91846, AUC: 0.8559007566987991, MCC: 0.3413326842506679, sum: 12413.0\n",
      "Epoch: 187 | Loss: 0.59196, Accuracy: 87.24% | Test loss: 0.91073, AUC: 0.8558212496823154, MCC: 0.34184636095831644, sum: 12318.0\n",
      "Epoch: 188 | Loss: 0.69470, Accuracy: 87.27% | Test loss: 0.90511, AUC: 0.8557702211521726, MCC: 0.34204585825485095, sum: 12285.0\n",
      "Epoch: 189 | Loss: 0.75463, Accuracy: 87.01% | Test loss: 0.91526, AUC: 0.8558795257234185, MCC: 0.3402303508360823, sum: 12547.0\n",
      "Epoch: 190 | Loss: 0.66796, Accuracy: 87.16% | Test loss: 0.91182, AUC: 0.8556987303220536, MCC: 0.3413858284567647, sum: 12395.0\n",
      "Epoch: 191 | Loss: 0.72338, Accuracy: 87.03% | Test loss: 0.92039, AUC: 0.8556388566681318, MCC: 0.34037632446340443, sum: 12524.0\n",
      "Epoch: 192 | Loss: 0.68233, Accuracy: 87.02% | Test loss: 0.90922, AUC: 0.8557530130006874, MCC: 0.3399493916384296, sum: 12531.0\n",
      "Epoch: 193 | Loss: 0.72765, Accuracy: 87.22% | Test loss: 0.90558, AUC: 0.8557214397253906, MCC: 0.3419393029906688, sum: 12336.0\n",
      "Epoch: 194 | Loss: 0.72756, Accuracy: 87.02% | Test loss: 0.90595, AUC: 0.8559565472668162, MCC: 0.34001964150956765, sum: 12535.0\n",
      "Epoch: 195 | Loss: 0.60069, Accuracy: 87.04% | Test loss: 0.90365, AUC: 0.8558943100029822, MCC: 0.3401976959124147, sum: 12518.0\n",
      "Epoch: 196 | Loss: 0.70098, Accuracy: 86.91% | Test loss: 0.90913, AUC: 0.8558061319529681, MCC: 0.3390819506393492, sum: 12646.0\n",
      "Epoch: 197 | Loss: 0.67745, Accuracy: 87.04% | Test loss: 0.90380, AUC: 0.8555672359399044, MCC: 0.3396041924226168, sum: 12503.0\n",
      "Epoch: 198 | Loss: 0.60946, Accuracy: 87.10% | Test loss: 0.90007, AUC: 0.855904012186446, MCC: 0.34041545195120065, sum: 12453.0\n",
      "Epoch: 199 | Loss: 0.58437, Accuracy: 86.90% | Test loss: 0.91018, AUC: 0.8558030934085541, MCC: 0.3387470246411941, sum: 12656.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.9780298007859125,\n",
       "  1.4441742499669392,\n",
       "  1.198435644308726,\n",
       "  1.0958315995004442,\n",
       "  1.0394750403033362,\n",
       "  0.999583770831426,\n",
       "  0.9780301915274726,\n",
       "  0.9571505486965179,\n",
       "  0.9437823659843869,\n",
       "  0.9233224822415246,\n",
       "  0.9110089706050025,\n",
       "  0.8997445603211721,\n",
       "  0.8815844423241086,\n",
       "  0.8744452893733978,\n",
       "  0.861532555686103,\n",
       "  0.8513534896903567,\n",
       "  0.8420613474316068,\n",
       "  0.8328515589237213,\n",
       "  0.8270929323302375,\n",
       "  0.8227197064293755,\n",
       "  0.8170174625184801,\n",
       "  0.8085716896586947,\n",
       "  0.8053434954749213,\n",
       "  0.7974164187908173,\n",
       "  0.7935640149646335,\n",
       "  0.7899925841225518,\n",
       "  0.7853214177820418,\n",
       "  0.7804101142618391,\n",
       "  0.7770180172390408,\n",
       "  0.7783757348855337,\n",
       "  0.7736527389950223,\n",
       "  0.773956322007709,\n",
       "  0.7680418988068899,\n",
       "  0.7654115226533678,\n",
       "  0.758845653798845,\n",
       "  0.7572651207447052,\n",
       "  0.7567404574818082,\n",
       "  0.7549782594045004,\n",
       "  0.7501677374045054,\n",
       "  0.7509016295274099,\n",
       "  0.7513318889670901,\n",
       "  0.7470822268062167,\n",
       "  0.7475545638137393,\n",
       "  0.7442335718207889,\n",
       "  0.7445328964127435,\n",
       "  0.7418992585606046,\n",
       "  0.7389209204249911,\n",
       "  0.7378239764107598,\n",
       "  0.7395323514938354,\n",
       "  0.7338282697730594,\n",
       "  0.7330106132560306,\n",
       "  0.7349574863910675,\n",
       "  0.737292617559433,\n",
       "  0.7308899362881979,\n",
       "  0.7309476070933871,\n",
       "  0.7298770580026839,\n",
       "  0.7283952368630303,\n",
       "  0.729315095477634,\n",
       "  0.7233170734511482,\n",
       "  0.7264086935255263,\n",
       "  0.7226402693324618,\n",
       "  0.7256517873870002,\n",
       "  0.7198140687412686,\n",
       "  0.7255375650193956,\n",
       "  0.7209440966447195,\n",
       "  0.7167847355206808,\n",
       "  0.7190828190909492,\n",
       "  0.7178271247280968,\n",
       "  0.7174658046828376,\n",
       "  0.7181385060151418,\n",
       "  0.7158725029892392,\n",
       "  0.7149356173144447,\n",
       "  0.7127841942840152,\n",
       "  0.7126961383554671,\n",
       "  0.7139952580134074,\n",
       "  0.7144433392418755,\n",
       "  0.7141239808665382,\n",
       "  0.7125776774353452,\n",
       "  0.7113389273484548,\n",
       "  0.7090977364116244,\n",
       "  0.7113754881752862,\n",
       "  0.709704253408644,\n",
       "  0.7101723253726959,\n",
       "  0.7055991590023041,\n",
       "  0.7068467636903127,\n",
       "  0.7051968309614394,\n",
       "  0.7059493727154202,\n",
       "  0.7036241888999939,\n",
       "  0.7041587928930918,\n",
       "  0.7053055829472012,\n",
       "  0.7052815059820811,\n",
       "  0.7067484127150642,\n",
       "  0.7081915967994266,\n",
       "  0.7069203323788114,\n",
       "  0.704279836681154,\n",
       "  0.7045048243469663,\n",
       "  0.7044157915645175,\n",
       "  0.7010196248690287,\n",
       "  0.7020332018534342,\n",
       "  0.7039828532271915,\n",
       "  0.7023053897751702,\n",
       "  0.6996790766716003,\n",
       "  0.698693636390898,\n",
       "  0.7007144027286105,\n",
       "  0.6951760914590623,\n",
       "  0.6971522867679596,\n",
       "  0.6933647261725532,\n",
       "  0.6988165908389621,\n",
       "  0.6985010438495212,\n",
       "  0.6973338094022539,\n",
       "  0.6932416955629984,\n",
       "  0.6956568128532834,\n",
       "  0.6943741705682542,\n",
       "  0.6945337719387479,\n",
       "  0.694398088587655,\n",
       "  0.6976051959726546,\n",
       "  0.695186479224099,\n",
       "  0.6935190061728159,\n",
       "  0.6950909694035848,\n",
       "  0.6928468114799924,\n",
       "  0.6913568841086494,\n",
       "  0.6945953369140625,\n",
       "  0.6983843048413595,\n",
       "  0.6934423877133263,\n",
       "  0.6959830423196157,\n",
       "  0.6931592093573676,\n",
       "  0.6904330319828458,\n",
       "  0.6928543415334489,\n",
       "  0.6894754767417908,\n",
       "  0.6893811358345879,\n",
       "  0.6909677816761864,\n",
       "  0.68956192334493,\n",
       "  0.690671917464998,\n",
       "  0.6885619825787015,\n",
       "  0.6890270147058699,\n",
       "  0.6915355755223168,\n",
       "  0.6869533558686575,\n",
       "  0.6879387166765001,\n",
       "  0.6844090951813592,\n",
       "  0.683004402452045,\n",
       "  0.6884424984455109,\n",
       "  0.6873747706413269,\n",
       "  0.686417755153444,\n",
       "  0.6842272844579484,\n",
       "  0.6841992371612124,\n",
       "  0.6839913460943434,\n",
       "  0.6862717767556509,\n",
       "  0.689759330617057,\n",
       "  0.6832739644580417,\n",
       "  0.6899408996105194,\n",
       "  0.6853972772757212,\n",
       "  0.6835782892174191,\n",
       "  0.6829536822107103,\n",
       "  0.6817160016960568,\n",
       "  0.6808605657683479,\n",
       "  0.6811726556883918,\n",
       "  0.6843296388785044,\n",
       "  0.6800664365291595,\n",
       "  0.6805741455819871,\n",
       "  0.6817008256912231,\n",
       "  0.6833449602127075,\n",
       "  0.6795607341660393,\n",
       "  0.6822833021481832,\n",
       "  0.6789467102951474,\n",
       "  0.6846808426909976,\n",
       "  0.6772821611828275,\n",
       "  0.6847218639320798,\n",
       "  0.6830964750713773,\n",
       "  0.6788254115316603,\n",
       "  0.6811564630932279,\n",
       "  0.6770304176542494,\n",
       "  0.6759622130129073,\n",
       "  0.6783403489324782,\n",
       "  0.6767119202348921,\n",
       "  0.6772621009084914,\n",
       "  0.6786083877086639,\n",
       "  0.6779037084844377,\n",
       "  0.6783377130826315,\n",
       "  0.6762129432625241,\n",
       "  0.6753760940498776,\n",
       "  0.6777219043837653,\n",
       "  0.67687812116411,\n",
       "  0.6737882263130612,\n",
       "  0.6770728760295444,\n",
       "  0.6758438679907057,\n",
       "  0.6799575355317857,\n",
       "  0.6742181413703494,\n",
       "  0.6750395860936906,\n",
       "  0.6776178876558939,\n",
       "  0.6762732399834527,\n",
       "  0.6748025351100497,\n",
       "  0.6724490821361542,\n",
       "  0.6748014622264438,\n",
       "  0.6726520160833994,\n",
       "  0.6737895409266154,\n",
       "  0.669904758532842,\n",
       "  0.6742076211505466,\n",
       "  0.6707595222526126,\n",
       "  0.6668275627824995,\n",
       "  0.6722671952512529],\n",
       " [array(1.0580249, dtype=float32),\n",
       "  array(1.0584188, dtype=float32),\n",
       "  array(1.0542315, dtype=float32),\n",
       "  array(1.0653709, dtype=float32),\n",
       "  array(1.067422, dtype=float32),\n",
       "  array(1.068156, dtype=float32),\n",
       "  array(1.0681641, dtype=float32),\n",
       "  array(1.0677505, dtype=float32),\n",
       "  array(1.0654937, dtype=float32),\n",
       "  array(1.0637, dtype=float32),\n",
       "  array(1.0581484, dtype=float32),\n",
       "  array(1.0499848, dtype=float32),\n",
       "  array(1.041056, dtype=float32),\n",
       "  array(1.0288275, dtype=float32),\n",
       "  array(1.0209982, dtype=float32),\n",
       "  array(1.0116829, dtype=float32),\n",
       "  array(1.0021629, dtype=float32),\n",
       "  array(0.9961868, dtype=float32),\n",
       "  array(0.99058056, dtype=float32),\n",
       "  array(0.98355174, dtype=float32),\n",
       "  array(0.9840637, dtype=float32),\n",
       "  array(0.9845669, dtype=float32),\n",
       "  array(0.97425705, dtype=float32),\n",
       "  array(0.9715996, dtype=float32),\n",
       "  array(0.9707739, dtype=float32),\n",
       "  array(0.97788787, dtype=float32),\n",
       "  array(0.9695161, dtype=float32),\n",
       "  array(0.9706961, dtype=float32),\n",
       "  array(0.97069246, dtype=float32),\n",
       "  array(0.9720103, dtype=float32),\n",
       "  array(0.9673716, dtype=float32),\n",
       "  array(0.96706486, dtype=float32),\n",
       "  array(0.9652354, dtype=float32),\n",
       "  array(0.97041774, dtype=float32),\n",
       "  array(0.9577588, dtype=float32),\n",
       "  array(0.96460867, dtype=float32),\n",
       "  array(0.9564145, dtype=float32),\n",
       "  array(0.9612255, dtype=float32),\n",
       "  array(0.96350074, dtype=float32),\n",
       "  array(0.96039605, dtype=float32),\n",
       "  array(0.96383685, dtype=float32),\n",
       "  array(0.9572206, dtype=float32),\n",
       "  array(0.9573463, dtype=float32),\n",
       "  array(0.9499252, dtype=float32),\n",
       "  array(0.9510215, dtype=float32),\n",
       "  array(0.9511387, dtype=float32),\n",
       "  array(0.9446318, dtype=float32),\n",
       "  array(0.94702846, dtype=float32),\n",
       "  array(0.9444265, dtype=float32),\n",
       "  array(0.9502282, dtype=float32),\n",
       "  array(0.94692713, dtype=float32),\n",
       "  array(0.94845283, dtype=float32),\n",
       "  array(0.93325955, dtype=float32),\n",
       "  array(0.9620815, dtype=float32),\n",
       "  array(0.9490374, dtype=float32),\n",
       "  array(0.9439774, dtype=float32),\n",
       "  array(0.93030804, dtype=float32),\n",
       "  array(0.9414011, dtype=float32),\n",
       "  array(0.94621617, dtype=float32),\n",
       "  array(0.93878615, dtype=float32),\n",
       "  array(0.9448019, dtype=float32),\n",
       "  array(0.93441755, dtype=float32),\n",
       "  array(0.947512, dtype=float32),\n",
       "  array(0.9333037, dtype=float32),\n",
       "  array(0.94936585, dtype=float32),\n",
       "  array(0.9375349, dtype=float32),\n",
       "  array(0.9440404, dtype=float32),\n",
       "  array(0.9485569, dtype=float32),\n",
       "  array(0.9386798, dtype=float32),\n",
       "  array(0.9447512, dtype=float32),\n",
       "  array(0.9425824, dtype=float32),\n",
       "  array(0.94911706, dtype=float32),\n",
       "  array(0.9352727, dtype=float32),\n",
       "  array(0.924861, dtype=float32),\n",
       "  array(0.9290243, dtype=float32),\n",
       "  array(0.9461979, dtype=float32),\n",
       "  array(0.9305572, dtype=float32),\n",
       "  array(0.9310782, dtype=float32),\n",
       "  array(0.9333183, dtype=float32),\n",
       "  array(0.9252427, dtype=float32),\n",
       "  array(0.9217015, dtype=float32),\n",
       "  array(0.93836206, dtype=float32),\n",
       "  array(0.9241515, dtype=float32),\n",
       "  array(0.93472666, dtype=float32),\n",
       "  array(0.9239296, dtype=float32),\n",
       "  array(0.93040186, dtype=float32),\n",
       "  array(0.9220991, dtype=float32),\n",
       "  array(0.93644285, dtype=float32),\n",
       "  array(0.9235726, dtype=float32),\n",
       "  array(0.9364207, dtype=float32),\n",
       "  array(0.91568905, dtype=float32),\n",
       "  array(0.9234967, dtype=float32),\n",
       "  array(0.93631196, dtype=float32),\n",
       "  array(0.92064315, dtype=float32),\n",
       "  array(0.9194928, dtype=float32),\n",
       "  array(0.91401845, dtype=float32),\n",
       "  array(0.9330295, dtype=float32),\n",
       "  array(0.9342383, dtype=float32),\n",
       "  array(0.92882997, dtype=float32),\n",
       "  array(0.9245325, dtype=float32),\n",
       "  array(0.9400416, dtype=float32),\n",
       "  array(0.9286423, dtype=float32),\n",
       "  array(0.93379134, dtype=float32),\n",
       "  array(0.9210874, dtype=float32),\n",
       "  array(0.92306703, dtype=float32),\n",
       "  array(0.9211085, dtype=float32),\n",
       "  array(0.92787045, dtype=float32),\n",
       "  array(0.92490214, dtype=float32),\n",
       "  array(0.92296666, dtype=float32),\n",
       "  array(0.9249552, dtype=float32),\n",
       "  array(0.9249753, dtype=float32),\n",
       "  array(0.9248433, dtype=float32),\n",
       "  array(0.9248783, dtype=float32),\n",
       "  array(0.92442083, dtype=float32),\n",
       "  array(0.9171737, dtype=float32),\n",
       "  array(0.92899615, dtype=float32),\n",
       "  array(0.92506737, dtype=float32),\n",
       "  array(0.9127385, dtype=float32),\n",
       "  array(0.9104262, dtype=float32),\n",
       "  array(0.932151, dtype=float32),\n",
       "  array(0.91420174, dtype=float32),\n",
       "  array(0.91588956, dtype=float32),\n",
       "  array(0.91993606, dtype=float32),\n",
       "  array(0.9368865, dtype=float32),\n",
       "  array(0.91198593, dtype=float32),\n",
       "  array(0.9315888, dtype=float32),\n",
       "  array(0.9267469, dtype=float32),\n",
       "  array(0.9103224, dtype=float32),\n",
       "  array(0.9282392, dtype=float32),\n",
       "  array(0.9185109, dtype=float32),\n",
       "  array(0.91988605, dtype=float32),\n",
       "  array(0.9238051, dtype=float32),\n",
       "  array(0.92417204, dtype=float32),\n",
       "  array(0.9162796, dtype=float32),\n",
       "  array(0.9210021, dtype=float32),\n",
       "  array(0.92030877, dtype=float32),\n",
       "  array(0.93101823, dtype=float32),\n",
       "  array(0.92559403, dtype=float32),\n",
       "  array(0.9207326, dtype=float32),\n",
       "  array(0.92974305, dtype=float32),\n",
       "  array(0.90900487, dtype=float32),\n",
       "  array(0.91155964, dtype=float32),\n",
       "  array(0.91080475, dtype=float32),\n",
       "  array(0.9032412, dtype=float32),\n",
       "  array(0.91297275, dtype=float32),\n",
       "  array(0.9236744, dtype=float32),\n",
       "  array(0.9219818, dtype=float32),\n",
       "  array(0.9230109, dtype=float32),\n",
       "  array(0.9230602, dtype=float32),\n",
       "  array(0.9079907, dtype=float32),\n",
       "  array(0.9141927, dtype=float32),\n",
       "  array(0.9241768, dtype=float32),\n",
       "  array(0.93252426, dtype=float32),\n",
       "  array(0.91650754, dtype=float32),\n",
       "  array(0.9177795, dtype=float32),\n",
       "  array(0.91852856, dtype=float32),\n",
       "  array(0.91648835, dtype=float32),\n",
       "  array(0.92974746, dtype=float32),\n",
       "  array(0.9173332, dtype=float32),\n",
       "  array(0.91253936, dtype=float32),\n",
       "  array(0.909561, dtype=float32),\n",
       "  array(0.91657704, dtype=float32),\n",
       "  array(0.92211694, dtype=float32),\n",
       "  array(0.92613816, dtype=float32),\n",
       "  array(0.90949994, dtype=float32),\n",
       "  array(0.914887, dtype=float32),\n",
       "  array(0.9137392, dtype=float32),\n",
       "  array(0.91001725, dtype=float32),\n",
       "  array(0.9207276, dtype=float32),\n",
       "  array(0.911265, dtype=float32),\n",
       "  array(0.9241516, dtype=float32),\n",
       "  array(0.9151588, dtype=float32),\n",
       "  array(0.8963423, dtype=float32),\n",
       "  array(0.90661913, dtype=float32),\n",
       "  array(0.91061926, dtype=float32),\n",
       "  array(0.92125916, dtype=float32),\n",
       "  array(0.9205343, dtype=float32),\n",
       "  array(0.91097105, dtype=float32),\n",
       "  array(0.9101969, dtype=float32),\n",
       "  array(0.92489094, dtype=float32),\n",
       "  array(0.9181487, dtype=float32),\n",
       "  array(0.9161093, dtype=float32),\n",
       "  array(0.9040581, dtype=float32),\n",
       "  array(0.90519935, dtype=float32),\n",
       "  array(0.91029704, dtype=float32),\n",
       "  array(0.9031446, dtype=float32),\n",
       "  array(0.9184641, dtype=float32),\n",
       "  array(0.9107332, dtype=float32),\n",
       "  array(0.9051055, dtype=float32),\n",
       "  array(0.9152643, dtype=float32),\n",
       "  array(0.9118171, dtype=float32),\n",
       "  array(0.92039424, dtype=float32),\n",
       "  array(0.90921736, dtype=float32),\n",
       "  array(0.90557957, dtype=float32),\n",
       "  array(0.9059468, dtype=float32),\n",
       "  array(0.90365076, dtype=float32),\n",
       "  array(0.9091258, dtype=float32),\n",
       "  array(0.90380317, dtype=float32),\n",
       "  array(0.90007323, dtype=float32),\n",
       "  array(0.9101761, dtype=float32)])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(train_proteins, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_proteins, batch_size=len(test_proteins))\n",
    "\n",
    "\n",
    "class_weights = torch.tensor([ 0.5235, 11.1424], device='cuda:0')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                            lr=0.0001)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def train(model, optimizer, epochs, loss_fn, train_dataloader, test_dataloader):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # compute class weights (because the dataset is heavily imbalanced)\n",
    "    print(f'Class weights: ', class_weights)\n",
    "    # BCEWithLogitsLoss - sigmoid is already built-in!\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #\n",
    "        # TEST\n",
    "        #\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for batch_id, data in enumerate(test_dataloader):   \n",
    "                X_test = data.x.to(device)\n",
    "                y_test = data.y.to(device).float()\n",
    "                edges = data.edge_index.to(device)\n",
    "\n",
    "                test_logits = model(X_test, edges).squeeze()\n",
    "                test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "                test_loss = loss_fn(test_logits,\n",
    "                                    y_test)\n",
    "                test_losses.append(test_loss.cpu().detach().numpy())\n",
    "\n",
    "                # compute metrics on test dataset\n",
    "                test_acc = accuracy_fn(y_true=y_test,\n",
    "                                       y_pred=test_pred)\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(y_test.cpu().numpy(), torch.sigmoid(test_logits).cpu().numpy())\n",
    "                roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "                mcc = metrics.matthews_corrcoef(y_test.cpu().numpy(), test_pred.cpu().numpy())\n",
    "\n",
    "        #\n",
    "        # TRAIN\n",
    "        #\n",
    "        batch_losses = []\n",
    "        for id_batch, data in enumerate(train_dataloader):\n",
    "            x_batch = data.x.to(device)\n",
    "            y_batch = data.y.to(device).float()\n",
    "            edges = data.edge_index.to(device)\n",
    "            model.train()\n",
    "\n",
    "            y_logits = model(x_batch, edges).squeeze()\n",
    "            y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "            loss = loss_fn(y_logits,\n",
    "                           y_batch)\n",
    "            acc = accuracy_fn(y_true=y_batch,\n",
    "                              y_pred=y_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        train_losses.append(sum(batch_losses) / len(batch_losses))\n",
    "        #if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {test_acc:.2f}% | Test loss: {test_loss:.5f}, AUC: {roc_auc}, MCC: {mcc}, sum: {sum(test_pred)}\")\n",
    "    return train_losses, test_losses\n",
    "train_losses, test_losses = train(model, optimizer, 200, loss_fn, train_loader, test_loader)\n",
    "\n",
    "# before\n",
    "# Epoch: 9 | Loss: 0.56604, Accuracy: 88.67% | Test loss: 0.76909, AUC: 0.8404747014689036, MCC: 0.3271917471805186, sum: 10366.0\n",
    "\n",
    "# between\n",
    "# Epoch: 9 | Loss: 0.55879, Accuracy: 88.88% | Test loss: 0.76789, AUC: 0.8405509543368965, MCC: 0.3288717653870401, sum: 10141.0\n",
    "\n",
    "# GAT\n",
    "# Epoch: 99 | Loss: 0.49741, Accuracy: 83.00% | Test loss: 0.77240, AUC: 0.8372716739098521, MCC: 0.29271584249931554, sum: 16152.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROPOUT = 0.3\n",
    "EMBEDDING_DIM = 2560\n",
    "HEADS = 16\n",
    "HIDDEN_CHANNELS = 8\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        # self.conv1 = GATConv(EMBEDDING_DIM, HIDDEN_CHANNELS, heads=HEADS, dropout=DROPOUT)\n",
    "        self.linear1 = nn.Linear(EMBEDDING_DIM, HIDDEN_CHANNELS * HEADS)\n",
    "        # self.conv2 = GATConv(HIDDEN_CHANNELS * HEADS, 1, heads=1, dropout=DROPOUT)\n",
    "        self.dropout1 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.linear2 = nn.Linear(in_features=HIDDEN_CHANNELS * HEADS, out_features=HIDDEN_CHANNELS * HEADS)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.linear3 = nn.Linear(in_features=HIDDEN_CHANNELS * HEADS, out_features=1)\n",
    "        self.dropout3 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x = F.dropout(x, p=DROPOUT, training=self.training)\n",
    "        \n",
    "        # x = self.conv1(x, edge_index)\n",
    "\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.dropout3(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.82122, Accuracy: 87.68% | Test loss: 0.81590, AUC: 0.7007573512359389, MCC: 0.27451946167671926, sum: 10611.0\n",
      "Epoch: 2 | Loss: 0.62505, Accuracy: 87.71% | Test loss: 0.77452, AUC: 0.726788032263894, MCC: 0.30430126299541016, sum: 11091.0\n",
      "Epoch: 3 | Loss: 0.51202, Accuracy: 88.19% | Test loss: 0.75662, AUC: 0.7354786214858118, MCC: 0.31956952555210544, sum: 10800.0\n",
      "Epoch: 4 | Loss: 0.66332, Accuracy: 87.59% | Test loss: 0.74778, AUC: 0.7467993300246597, MCC: 0.3249600637796976, sum: 11596.0\n",
      "Epoch: 5 | Loss: 0.68349, Accuracy: 87.87% | Test loss: 0.74795, AUC: 0.7462397490606378, MCC: 0.3276300546174695, sum: 11313.0\n",
      "Epoch: 6 | Loss: 0.54107, Accuracy: 87.57% | Test loss: 0.74550, AUC: 0.7519145541598419, MCC: 0.3302353309775568, sum: 11718.0\n",
      "Epoch: 7 | Loss: 0.51086, Accuracy: 87.84% | Test loss: 0.75372, AUC: 0.7483210100336968, MCC: 0.3294996979953315, sum: 11386.0\n",
      "Epoch: 8 | Loss: 0.63426, Accuracy: 87.67% | Test loss: 0.76050, AUC: 0.7516218334594135, MCC: 0.3310690692686598, sum: 11616.0\n",
      "Epoch: 9 | Loss: 0.54470, Accuracy: 88.48% | Test loss: 0.78860, AUC: 0.7466895527314313, MCC: 0.33565071886762915, sum: 10735.0\n",
      "Epoch: 10 | Loss: 0.71392, Accuracy: 89.16% | Test loss: 0.81688, AUC: 0.738964971550185, MCC: 0.3362077571285047, sum: 9934.0\n",
      "Epoch: 11 | Loss: 0.41249, Accuracy: 89.09% | Test loss: 0.83218, AUC: 0.7398223030836609, MCC: 0.3361677917604115, sum: 10019.0\n",
      "Epoch: 12 | Loss: 0.30790, Accuracy: 89.03% | Test loss: 0.86003, AUC: 0.7379802581818915, MCC: 0.33331161370949514, sum: 10038.0\n",
      "Epoch: 13 | Loss: 0.40261, Accuracy: 90.03% | Test loss: 0.92383, AUC: 0.7273313063282557, MCC: 0.33611693035338197, sum: 8871.0\n",
      "Epoch: 14 | Loss: 0.37985, Accuracy: 90.51% | Test loss: 0.99061, AUC: 0.7179632877573366, MCC: 0.333287442921393, sum: 8225.0\n",
      "Epoch: 15 | Loss: 0.34199, Accuracy: 90.47% | Test loss: 1.04577, AUC: 0.7148475128916707, MCC: 0.3288271599856827, sum: 8208.0\n",
      "Epoch: 16 | Loss: 0.33980, Accuracy: 90.43% | Test loss: 1.06693, AUC: 0.7205832991266082, MCC: 0.3348504247349862, sum: 8360.0\n",
      "Epoch: 17 | Loss: 0.28982, Accuracy: 91.76% | Test loss: 1.22345, AUC: 0.6947831202834281, MCC: 0.3297333293996574, sum: 6571.0\n",
      "Epoch: 18 | Loss: 0.31095, Accuracy: 90.79% | Test loss: 1.20583, AUC: 0.7081351526771346, MCC: 0.3265657515333446, sum: 7766.0\n",
      "Epoch: 19 | Loss: 0.25151, Accuracy: 91.65% | Test loss: 1.34087, AUC: 0.694270756612263, MCC: 0.3265529207530753, sum: 6673.0\n",
      "Epoch: 20 | Loss: 0.24623, Accuracy: 91.80% | Test loss: 1.41020, AUC: 0.6927326130223421, MCC: 0.3280547446371746, sum: 6493.0\n",
      "Epoch: 21 | Loss: 0.20788, Accuracy: 91.45% | Test loss: 1.40183, AUC: 0.7008072602318683, MCC: 0.33037339794608034, sum: 6994.0\n",
      "Epoch: 22 | Loss: 0.21294, Accuracy: 91.66% | Test loss: 1.47123, AUC: 0.6932024477849578, MCC: 0.3254729357890204, sum: 6641.0\n",
      "Epoch: 23 | Loss: 0.22559, Accuracy: 92.51% | Test loss: 1.66386, AUC: 0.676751835285513, MCC: 0.3248332337322027, sum: 5501.0\n",
      "Epoch: 24 | Loss: 0.30175, Accuracy: 92.13% | Test loss: 1.62456, AUC: 0.6869754016344392, MCC: 0.3284342711402366, sum: 6064.0\n",
      "Epoch: 25 | Loss: 0.11997, Accuracy: 92.41% | Test loss: 1.78654, AUC: 0.6756908663709152, MCC: 0.3207472541849138, sum: 5580.0\n",
      "Epoch: 26 | Loss: 0.26910, Accuracy: 92.28% | Test loss: 1.79084, AUC: 0.6828141371555775, MCC: 0.3266893917559785, sum: 5843.0\n",
      "Epoch: 27 | Loss: 0.27618, Accuracy: 92.37% | Test loss: 1.85792, AUC: 0.6778563856850859, MCC: 0.3226115210492846, sum: 5658.0\n",
      "Epoch: 28 | Loss: 0.13727, Accuracy: 92.59% | Test loss: 1.95668, AUC: 0.6695510514872901, MCC: 0.31739309296468915, sum: 5288.0\n",
      "Epoch: 29 | Loss: 0.15440, Accuracy: 92.68% | Test loss: 2.00398, AUC: 0.6674876481562586, MCC: 0.31725880551412017, sum: 5156.0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 12\n",
    "train_loader = DataLoader(train_proteins, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_proteins, batch_size=len(test_proteins), shuffle=True)\n",
    "\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "class_weights = torch.tensor([ 0.5235, 11.1424], device='cuda:0')\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def train(train_loader, test_loader):\n",
    "    batch_losses = []\n",
    "    for batch_id, data in enumerate(train_loader):  \n",
    "        model.train()\n",
    "        optimizer.zero_grad()  \n",
    "        out = model(data.x.to(device), data.edge_index.to(device)).squeeze()\n",
    "\n",
    "        loss = criterion(out, data.y.float().to(device))  # Compute the loss solely based on the training nodes.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        batch_losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    for batch_id, data in enumerate(test_loader):  \n",
    "        model.eval()\n",
    "        test_logits = model(data.x.to(device), data.edge_index.to(device)).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits)).cpu()\n",
    "\n",
    "        test_loss = criterion(test_logits, data.y.float().to(device))\n",
    "        \n",
    "        test_acc = accuracy_fn(y_true=data.y,\n",
    "                                y_pred=test_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(data.y.numpy(), torch.sigmoid(test_pred).detach().numpy())\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        mcc = metrics.matthews_corrcoef(data.y.numpy(), test_pred.detach().numpy())\n",
    "    print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {test_acc:.2f}% | Test loss: {test_loss:.5f}, AUC: {roc_auc}, MCC: {mcc}, sum: {sum(test_pred)}\")\n",
    "    return loss.cpu().detach().numpy(), test_loss.cpu().detach().numpy()\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "for epoch in range(1, 30):\n",
    "    loss, test_loss = train(train_loader, test_loader)\n",
    "    test_losses.append(loss)\n",
    "    train_losses.append(test_loss)\n",
    "\n",
    "    # TODO: GCN to GAT, maybe add Linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses,label=\"train loss over epochs\")\n",
    "plt.plot(test_losses,label=\"test loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for batch_id, data in enumerate(test_loader): \n",
    "    print(batch_id)\n",
    "    assert data.edge_index.max() < data.x.size(0), f'{data.edge_index.max()}, {data.x.size(0)}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
